{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d43ac3e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ok\n"
     ]
    }
   ],
   "source": [
    "print(\"Ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1c94e69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\End-to-End-Medical-Chatbot-Generative-AI\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8726b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbf1f3d",
   "metadata": {},
   "source": [
    "we are doing this step because we are in research folder and not in the root folder and we want these steps to apply on the whole root folde so we are going one directory back which is our root dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e605ca13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\End-to-End-Medical-Chatbot-Generative-AI'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b30821",
   "metadata": {},
   "source": [
    "Now we are in the correct root directory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58eb372b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2872da73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract Data From the PDF File\n",
    "def load_pdf_file(data):\n",
    "    loader= DirectoryLoader(data,\n",
    "                            glob=\"*.pdf\",\n",
    "                            loader_cls=PyPDFLoader)\n",
    "\n",
    "    documents=loader.load()\n",
    "\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7d34490",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data=load_pdf_file(data='Data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1457cd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "531a2bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the Data into Text Chunks\n",
    "def text_split(extracted_data):\n",
    "    text_splitter=RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)\n",
    "    text_chunks=text_splitter.split_documents(extracted_data)\n",
    "    return text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66854d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Text Chunks 5860\n"
     ]
    }
   ],
   "source": [
    "text_chunks=text_split(extracted_data)\n",
    "print(\"Length of Text Chunks\", len(text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "744ff9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3874a0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download the Embeddings from Hugging Face\n",
    "def download_hugging_face_embeddings():\n",
    "    embeddings=HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7c9e8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91987\\AppData\\Local\\Temp\\ipykernel_6488\\2661704553.py:3: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings=HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
      "c:\\End-to-End-Medical-Chatbot-Generative-AI\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\End-to-End-Medical-Chatbot-Generative-AI\\venv\\Lib\\site-packages\\transformers\\utils\\generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "c:\\End-to-End-Medical-Chatbot-Generative-AI\\venv\\Lib\\site-packages\\transformers\\utils\\generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "embeddings = download_hugging_face_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length 384\n"
     ]
    }
   ],
   "source": [
    "query_result = embeddings.embed_query(\"Hello world\")\n",
    "print(\"Length\", len(query_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c92c5abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#query_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7c14d9f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "21f5d18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY=os.environ.get('PINECONE_API_KEY')\n",
    "#OPENAI_API_KEY=os.environ.get('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "701d6b0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "    \"name\": \"medicalbot\",\n",
       "    \"metric\": \"cosine\",\n",
       "    \"host\": \"medicalbot-aejw4ys.svc.aped-4627-b74a.pinecone.io\",\n",
       "    \"spec\": {\n",
       "        \"serverless\": {\n",
       "            \"cloud\": \"aws\",\n",
       "            \"region\": \"us-east-1\"\n",
       "        }\n",
       "    },\n",
       "    \"status\": {\n",
       "        \"ready\": true,\n",
       "        \"state\": \"Ready\"\n",
       "    },\n",
       "    \"vector_type\": \"dense\",\n",
       "    \"dimension\": 384,\n",
       "    \"deletion_protection\": \"disabled\",\n",
       "    \"tags\": null\n",
       "}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pinecone.grpc import PineconeGRPC as Pinecone\n",
    "from pinecone import ServerlessSpec\n",
    "import os\n",
    "\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "index_name1 = \"medicalbot\"\n",
    "\n",
    "\n",
    "pc.create_index(\n",
    "    name=index_name1,\n",
    "    dimension=384, \n",
    "    metric=\"cosine\", \n",
    "    spec=ServerlessSpec(\n",
    "        cloud=\"aws\", \n",
    "        region=\"us-east-1\"\n",
    "    ) \n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "207a3a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PINECONE_API_KEY\"] = PINECONE_API_KEY\n",
    "#os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed each chunk and upsert the embeddings into your Pinecone index.\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "docsearch = PineconeVectorStore.from_documents(\n",
    "    documents=text_chunks,\n",
    "    index_name=index_name1,\n",
    "    embedding=embeddings, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e1d7f275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Existing index \n",
    "\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "# Embed each chunk and upsert the embeddings into your Pinecone index.\n",
    "docsearch = PineconeVectorStore.from_existing_index(\n",
    "    index_name=index_name1,\n",
    "    embedding=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c62d2bed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_pinecone.vectorstores.PineconeVectorStore at 0x1ff5e10ab50>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5346c19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = docsearch.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_docs = retriever.invoke(\"What is Acne?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d53271c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='77a2b7f6-e6ba-4ce0-9785-b79a9ebdf44c', metadata={'creationdate': '2004-12-18T17:00:02-05:00', 'creator': 'PyPDF', 'moddate': '2004-12-18T16:15:31-06:00', 'page': 39.0, 'page_label': '40', 'producer': 'PDFlib+PDI 5.0.0 (SunOS)', 'source': 'Data\\\\Medical_book.pdf', 'total_pages': 637.0}, page_content='GALE ENCYCLOPEDIA OF MEDICINE 226\\nAcne\\nGEM - 0001 to 0432 - A  10/22/03 1:41 PM  Page 26'),\n",
       " Document(id='06cf0cfb-a9bb-404a-ad97-0024337ec768', metadata={'creationdate': '2004-12-18T17:00:02-05:00', 'creator': 'PyPDF', 'moddate': '2004-12-18T16:15:31-06:00', 'page': 38.0, 'page_label': '39', 'producer': 'PDFlib+PDI 5.0.0 (SunOS)', 'source': 'Data\\\\Medical_book.pdf', 'total_pages': 637.0}, page_content='GALE ENCYCLOPEDIA OF MEDICINE 2 25\\nAcne\\nAcne vulgaris affecting a womanâ€™s face. Acne is the general\\nname given to a skin disorder in which the sebaceous\\nglands become inflamed.(Photograph by Biophoto Associ-\\nates, Photo Researchers, Inc. Reproduced by permission.)\\nGEM - 0001 to 0432 - A  10/22/03 1:41 PM  Page 25'),\n",
       " Document(id='683929cc-5959-48e2-919e-f6574e88747a', metadata={'creationdate': '2004-12-18T17:00:02-05:00', 'creator': 'PyPDF', 'moddate': '2004-12-18T16:15:31-06:00', 'page': 37.0, 'page_label': '38', 'producer': 'PDFlib+PDI 5.0.0 (SunOS)', 'source': 'Data\\\\Medical_book.pdf', 'total_pages': 637.0}, page_content='Acidosis see Respiratory acidosis; Renal\\ntubular acidosis; Metabolic acidosis\\nAcne\\nDefinition\\nAcne is a common skin disease characterized by\\npimples on the face, chest, and back. It occurs when the\\npores of the skin become clogged with oil, dead skin\\ncells, and bacteria.\\nDescription\\nAcne vulgaris, the medical term for common acne, is\\nthe most common skin disease. It affects nearly 17 million\\npeople in the United States. While acne can arise at any')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21584b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OPENAI_API_KEY=os.environ.get('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d914e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7a223509",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91987\\AppData\\Local\\Temp\\ipykernel_6488\\1906085018.py:6: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  llm = Ollama(model=\"mistral\", temperature=0.4)\n"
     ]
    }
   ],
   "source": [
    "# from langchain_openai import OpenAI\n",
    "# llm = OpenAI(temperature=0.4, max_tokens=500)\n",
    "from langchain_community.llms import Ollama\n",
    "\n",
    "# Load Mistral model via Ollama\n",
    "llm = Ollama(model=\"mistral\", temperature=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "69fae3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.chains import create_retrieval_chain\n",
    "# from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "# from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "# system_prompt = (\n",
    "#     \"You are an assistant for question-answering tasks. \"\n",
    "#     \"Use the following pieces of retrieved context to answer \"\n",
    "#     \"the question. If you don't know the answer, say that you \"\n",
    "#     \"don't know. Use three sentences maximum and keep the \"\n",
    "#     \"answer concise.\"\n",
    "#     \"\\n\\n\"\n",
    "#     \"{context}\"\n",
    "# )\n",
    "\n",
    "\n",
    "# prompt = ChatPromptTemplate.from_messages(\n",
    "#     [\n",
    "#         (\"system\", system_prompt),\n",
    "#         (\"human\", \"{input}\"),\n",
    "#     ]\n",
    "# )\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "# rag_chain = create_retrieval_chain(retriever, question_answer_chain)\n",
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "609c4ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Acromegaly is a disorder caused by an abnormal release of growth hormone from the pituitary gland, leading to increased growth in bones and soft tissue. If it occurs during childhood, it's known as gigantism due to unusual height increase. In adults, when it happens after bone growth has stopped, it's called acromegaly. It's a relatively rare condition, affecting approximately 50 people per million. Symptoms often appear gradually and diagnosis is usually delayed until middle age.\n"
     ]
    }
   ],
   "source": [
    "# response = rag_chain.invoke({\"input\": \"what is Acromegaly and gigantism?\"})\n",
    "# print(response[\"answer\"])\n",
    "response = rag_chain.invoke({\"input\": \"what is Acromegaly and gigantism?\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9ad86c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Stats, in this context, refers to the results or findings from a complete blood count (CBC) test and an electrocardiogram (ECG). The CBC provides information about the different types of cells suspended in the liquid part of the blood, such as red blood cells, white blood cells, and platelets. An ECG measures the electrical activity of the heart over time to help diagnose and assess heart conditions.\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": \"What is stats?\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "09573bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Regular self-examinations for breast and testicular cancer can help detect them early.\n",
      "2. Limiting excessive alcohol consumption and avoiding excessive exposure to the sun are important in preventing liver cancer and melanoma respectively.\n",
      "3. For general cancer prevention, it's recommended to maintain a healthy lifestyle (balanced diet, regular exercise), avoid occupational exposure to harmful substances like vinyl chloride, lead, and pesticides, and consider genetic testing if there is a family history of certain cancers.\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": \"how to prevent ourself from cancer?\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b3fe3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
